{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cab1e2b-0b9a-475f-a9aa-ab9dfb36de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Data.csv', encoding='latin1')\n",
    "\n",
    "# Normalize the importance ratings\n",
    "for rating in ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1']:\n",
    "    df.loc[df[rating] > 10, rating] = df[rating] / 10\n",
    "\n",
    "# Handle missing data\n",
    "df = df.dropna(subset=['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1'])\n",
    "\n",
    "# Create a new dataframe for the pairs\n",
    "columns = ['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1']\n",
    "new_df = pd.DataFrame(columns=columns + ['match'])\n",
    "\n",
    "# Iterate over the rows of the original dataframe\n",
    "for i, row in df.iterrows():\n",
    "    # Find the partner row\n",
    "    partner_row = df[df['iid'] == row['pid']]\n",
    "    if partner_row.empty:\n",
    "        continue\n",
    "\n",
    "    # Compute the absolute difference of the ratings and add to the new dataframe\n",
    "    diff = np.abs(row[columns] - partner_row.iloc[0][columns])\n",
    "    diff['match'] = row['match']\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(diff).transpose()])\n",
    "\n",
    "# Save the new dataframe to a CSV file\n",
    "new_df.to_csv('NewData.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d9be13-de7c-44d7-911c-85c4a911c7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           attr3_1      sinc3_1     intel3_1       fun3_1       amb3_1  \\\n",
      "count  8122.000000  8122.000000  8122.000000  8122.000000  8122.000000   \n",
      "mean      1.505787     1.517360     1.151441     1.703275     1.956907   \n",
      "std       1.297238     1.324936     0.998689     1.426735     1.575382   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       1.000000     1.000000     0.000000     1.000000     1.000000   \n",
      "50%       1.000000     1.000000     1.000000     1.000000     2.000000   \n",
      "75%       2.000000     2.000000     2.000000     2.000000     3.000000   \n",
      "max       7.000000     8.000000     7.000000     8.000000     8.000000   \n",
      "\n",
      "           attr1_1      sinc1_1     intel1_1       fun1_1       amb1_1  \\\n",
      "count  8122.000000  8122.000000  8122.000000  8122.000000  8122.000000   \n",
      "mean      2.433962     2.276071     1.541192     2.352602     3.805449   \n",
      "std       2.790478     3.034659     2.512859     3.203256     3.399164   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.435000     0.200000     0.139000     0.172000     0.447000   \n",
      "50%       1.000000     0.500000     0.500000     0.500000     3.333000   \n",
      "75%       3.600000     3.000000     1.121000     3.500000     7.500000   \n",
      "max      10.000000    10.000000    10.000000    10.000000    10.000000   \n",
      "\n",
      "             match  \n",
      "count  8122.000000  \n",
      "mean      0.161537  \n",
      "std       0.368048  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       0.000000  \n",
      "max       1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new dataset\n",
    "df = pd.read_csv('NewData.csv')\n",
    "\n",
    "# Display a statistical summary of the dataset\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2d7f53-e50d-49e3-aca7-c0f4924b4f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "[[848 502]\n",
      " [ 48 227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.63      0.76      1350\n",
      "           1       0.31      0.83      0.45       275\n",
      "\n",
      "    accuracy                           0.66      1625\n",
      "   macro avg       0.63      0.73      0.60      1625\n",
      "weighted avg       0.84      0.66      0.70      1625\n",
      "\n",
      "Percentage Compatibility: [0.         0.22222222 0.         ... 0.66666667 0.11111111 0.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 2 is smaller than n_iter=5. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Train the model with the best parameters on the oversampled training set\u001b[39;00m\n\u001b[0;32m     40\u001b[0m best_model \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m---> 41\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_smote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_smote\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('NewData.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('match', axis=1)\n",
    "y = df['match']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    ('KNN', KNeighborsClassifier(), {'n_neighbors': list(range(1, 31))}),\n",
    "    ('SVM', SVC(probability=True), {'C': [0.1, 1], 'kernel': ['rbf']}),\n",
    "    ('Logistic Regression', LogisticRegression(), {'C': [0.001, 0.01]}),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(), {'n_estimators': [100], 'learning_rate': [0.1]})\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model, params in models:\n",
    "    # Tune hyperparameters using RandomizedSearchCV with reduced iterations\n",
    "    random_search = RandomizedSearchCV(model, params, n_iter=5)\n",
    "    random_search.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Train the model with the best parameters on the oversampled training set\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Print the confusion matrix and classification report\n",
    "    print(f'{name}:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Make probability predictions on the test set and print percentage compatibility\n",
    "    y_prob = best_model.predict_proba(X_test)\n",
    "    compatibility_percentage = y_prob[:, 1]\n",
    "    print(f'Percentage Compatibility: {compatibility_percentage}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550dba7b-7c65-45ba-86cd-9f4f23f591cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "Best parameters for KNN: {'weights': 'distance', 'n_neighbors': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1350\n",
      "           1       1.00      0.83      0.90       275\n",
      "\n",
      "    accuracy                           0.97      1625\n",
      "   macro avg       0.98      0.91      0.94      1625\n",
      "weighted avg       0.97      0.97      0.97      1625\n",
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.84038799 0.84038799 0.84038799        nan        nan\n",
      " 0.84038799        nan 0.84038799        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'penalty': 'l2', 'C': 0.001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      1350\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.83      1625\n",
      "   macro avg       0.42      0.50      0.45      1625\n",
      "weighted avg       0.69      0.83      0.75      1625\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1350\n",
      "           1       0.92      0.85      0.88       275\n",
      "\n",
      "    accuracy                           0.96      1625\n",
      "   macro avg       0.95      0.92      0.93      1625\n",
      "weighted avg       0.96      0.96      0.96      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the new dataset\n",
    "df = pd.read_csv('NewData.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('match', axis=1)\n",
    "y = df['match']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the models and their respective hyperparameters\n",
    "models = {\n",
    "    'KNN': (KNeighborsClassifier(), {'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']}),\n",
    "    'Logistic Regression': (LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(), {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 1], 'max_depth': range(3, 6)})\n",
    "}\n",
    "\n",
    "# Train each model and display their performance\n",
    "for name, (model, params) in models.items():\n",
    "    print(f'Training {name}...')\n",
    "    clf = RandomizedSearchCV(model, params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'Best parameters for {name}: {clf.best_params_}')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cc5ce8-7da4-4c53-9eb9-ff7db788cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "Best parameters for KNN: {'weights': 'distance', 'n_neighbors': 30}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1350\n",
      "           1       1.00      0.83      0.90       275\n",
      "\n",
      "    accuracy                           0.97      1625\n",
      "   macro avg       0.98      0.91      0.94      1625\n",
      "weighted avg       0.97      0.97      0.97      1625\n",
      "\n",
      "[[1350    0]\n",
      " [  48  227]]\n",
      "Training Logistic Regression...\n",
      "Best parameters for Logistic Regression: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      1350\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.83      1625\n",
      "   macro avg       0.42      0.50      0.45      1625\n",
      "weighted avg       0.69      0.83      0.75      1625\n",
      "\n",
      "[[1350    0]\n",
      " [ 275    0]]\n",
      "Training Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\N\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1350\n",
      "           1       0.92      0.85      0.88       275\n",
      "\n",
      "    accuracy                           0.96      1625\n",
      "   macro avg       0.95      0.92      0.93      1625\n",
      "weighted avg       0.96      0.96      0.96      1625\n",
      "\n",
      "[[1330   20]\n",
      " [  42  233]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the new dataset\n",
    "df = pd.read_csv('NewData.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('match', axis=1)\n",
    "y = df['match']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the models and their respective hyperparameters\n",
    "models = {\n",
    "    'KNN': (KNeighborsClassifier(), {'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']}),\n",
    "    'Logistic Regression': (LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'solver': ['liblinear', 'lbfgs']}),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(), {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 1], 'max_depth': range(3, 6)})\n",
    "}\n",
    "\n",
    "# Train each model and display their performance\n",
    "for name, (model, params) in models.items():\n",
    "    print(f'Training {name}...')\n",
    "    clf = RandomizedSearchCV(model, params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'Best parameters for {name}: {clf.best_params_}')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79cd355d-f9f9-46d2-b60d-d16bac4d0106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "Best parameters for KNN: {'weights': 'distance', 'n_neighbors': 28}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1350\n",
      "           1       1.00      0.83      0.90       275\n",
      "\n",
      "    accuracy                           0.97      1625\n",
      "   macro avg       0.98      0.91      0.94      1625\n",
      "weighted avg       0.97      0.97      0.97      1625\n",
      "\n",
      "[[1350    0]\n",
      " [  48  227]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['knn_model1.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the new dataset\n",
    "df = pd.read_csv('NewData.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('match', axis=1)\n",
    "y = df['match']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model and its respective hyperparameters\n",
    "model = KNeighborsClassifier()\n",
    "params = {'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "# Train the model\n",
    "print(f'Training KNN...')\n",
    "clf = RandomizedSearchCV(model, params)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'Best parameters for KNN: {clf.best_params_}')\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(clf, 'knn_model1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a21e0e5-6ec1-4440-b470-dbe67ad96862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1.) Attractiveness:  9\n",
      "2.) Sincerity:  7\n",
      "3.) Intelligence:  9\n",
      "4.) Fun:  6\n",
      "5.) Ambition:  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importance Ratings(1-10)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "6.) Attractiveness:  6\n",
      "7.) Sincerity:  8\n",
      "8.) Intelligence:  5\n",
      "9.) Fun:  7\n",
      "10.) Ambition:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1.) Attractiveness:  6\n",
      "2.) Sincerity:  4\n",
      "3.) Intelligence:  9\n",
      "4.) Fun:  4\n",
      "5.) Ambition:  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importance Ratings(1-10)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "6.) Attractiveness:  6\n",
      "7.) Sincerity:  8\n",
      "8.) Intelligence:  4\n",
      "9.) Fun:  7\n",
      "10.) Ambition:  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With a confidence level of 77.00%, the AI model predicts you are not likely to be a match.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('knn_model.pkl')\n",
    "\n",
    "# Ask for user inputs\n",
    "ratings = []\n",
    "for partner in ['PARTNER A', 'PARTNER B']:\n",
    "    print(f'\\n{partner}')\n",
    "    print('\\nSelf-ratings(1-10)')\n",
    "    ratings.append(float(input('1.) Attractiveness: ')))\n",
    "    ratings.append(float(input('2.) Sincerity: ')))\n",
    "    ratings.append(float(input('3.) Intelligence: ')))\n",
    "    ratings.append(float(input('4.) Fun: ')))\n",
    "    ratings.append(float(input('5.) Ambition: ')))\n",
    "    print('\\nImportance Ratings(1-10)')\n",
    "    ratings.append(float(input('6.) Attractiveness: ')))\n",
    "    ratings.append(float(input('7.) Sincerity: ')))\n",
    "    ratings.append(float(input('8.) Intelligence: ')))\n",
    "    ratings.append(float(input('9.) Fun: ')))\n",
    "    ratings.append(float(input('10.) Ambition: ')))\n",
    "\n",
    "# Preprocess the inputs to get the absolute difference of the partners' ratings\n",
    "inputs = np.abs(np.array(ratings[:10]) - np.array(ratings[10:]))\n",
    "\n",
    "# Feed the inputs to the model\n",
    "prediction = model.predict([inputs])\n",
    "probabilities = model.predict_proba([inputs])\n",
    "\n",
    "# Output the model's prediction\n",
    "if prediction[0] == 1:\n",
    "    print(f\"\\nWith a confidence level of {probabilities[0][1] * 100:.2f}%, the AI model predicts you are likely to be a match!\")\n",
    "else:\n",
    "    print(f\"\\nWith a confidence level of {probabilities[0][0] * 100:.2f}%, the AI model predicts you are not likely to be a match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e73a3727-c678-4af9-93ba-0747be8302f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Match 1] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 3\n",
      "Intelligence: 8\n",
      "Fun: 2\n",
      "Ambition: 1\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 1\n",
      "Intelligence: 7\n",
      "Fun: 3\n",
      "Ambition: 1\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 4\n",
      "Intelligence: 5\n",
      "Fun: 10\n",
      "Ambition: 1\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 1\n",
      "Intelligence: 7\n",
      "Fun: 3\n",
      "Ambition: 2\n",
      "\n",
      "Match 2] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 6\n",
      "Intelligence: 3\n",
      "Fun: 5\n",
      "Ambition: 5\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 2\n",
      "Intelligence: 7\n",
      "Fun: 7\n",
      "Ambition: 8\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 2\n",
      "Sincerity: 4\n",
      "Intelligence: 1\n",
      "Fun: 5\n",
      "Ambition: 5\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 2\n",
      "Intelligence: 7\n",
      "Fun: 4\n",
      "Ambition: 2\n",
      "\n",
      "Match 3] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 10\n",
      "Sincerity: 3\n",
      "Intelligence: 3\n",
      "Fun: 9\n",
      "Ambition: 4\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 10\n",
      "Intelligence: 8\n",
      "Fun: 10\n",
      "Ambition: 7\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 3\n",
      "Intelligence: 1\n",
      "Fun: 9\n",
      "Ambition: 2\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 7\n",
      "Sincerity: 10\n",
      "Intelligence: 8\n",
      "Fun: 9\n",
      "Ambition: 3\n",
      "\n",
      "Match 4] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 2\n",
      "Sincerity: 2\n",
      "Intelligence: 6\n",
      "Fun: 2\n",
      "Ambition: 10\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 2\n",
      "Sincerity: 7\n",
      "Intelligence: 7\n",
      "Fun: 6\n",
      "Ambition: 4\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 2\n",
      "Intelligence: 2\n",
      "Fun: 1\n",
      "Ambition: 10\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 2\n",
      "Sincerity: 10\n",
      "Intelligence: 7\n",
      "Fun: 3\n",
      "Ambition: 6\n",
      "\n",
      "Match 5] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 10\n",
      "Intelligence: 6\n",
      "Fun: 8\n",
      "Ambition: 1\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 7\n",
      "Sincerity: 2\n",
      "Intelligence: 9\n",
      "Fun: 6\n",
      "Ambition: 8\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 10\n",
      "Intelligence: 2\n",
      "Fun: 8\n",
      "Ambition: 3\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 1\n",
      "Intelligence: 9\n",
      "Fun: 4\n",
      "Ambition: 1\n",
      "\n",
      "Match 6] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 2\n",
      "Intelligence: 5\n",
      "Fun: 10\n",
      "Ambition: 9\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 2\n",
      "Intelligence: 2\n",
      "Fun: 4\n",
      "Ambition: 8\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 7\n",
      "Sincerity: 2\n",
      "Intelligence: 2\n",
      "Fun: 9\n",
      "Ambition: 8\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 2\n",
      "Intelligence: 1\n",
      "Fun: 6\n",
      "Ambition: 10\n",
      "\n",
      "Match 7] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 7\n",
      "Intelligence: 8\n",
      "Fun: 5\n",
      "Ambition: 1\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 7\n",
      "Sincerity: 4\n",
      "Intelligence: 4\n",
      "Fun: 3\n",
      "Ambition: 3\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 6\n",
      "Intelligence: 5\n",
      "Fun: 3\n",
      "Ambition: 1\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 3\n",
      "Intelligence: 4\n",
      "Fun: 5\n",
      "Ambition: 10\n",
      "\n",
      "Match 8] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 7\n",
      "Sincerity: 9\n",
      "Intelligence: 1\n",
      "Fun: 9\n",
      "Ambition: 8\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 1\n",
      "Intelligence: 6\n",
      "Fun: 5\n",
      "Ambition: 2\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 9\n",
      "Intelligence: 5\n",
      "Fun: 9\n",
      "Ambition: 7\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 4\n",
      "Intelligence: 7\n",
      "Fun: 9\n",
      "Ambition: 3\n",
      "\n",
      "Match 9] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 3\n",
      "Intelligence: 7\n",
      "Fun: 1\n",
      "Ambition: 10\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 10\n",
      "Sincerity: 9\n",
      "Intelligence: 9\n",
      "Fun: 7\n",
      "Ambition: 6\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 2\n",
      "Intelligence: 8\n",
      "Fun: 8\n",
      "Ambition: 10\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 7\n",
      "Sincerity: 8\n",
      "Intelligence: 9\n",
      "Fun: 6\n",
      "Ambition: 6\n",
      "\n",
      "Match 10] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 7\n",
      "Intelligence: 10\n",
      "Fun: 7\n",
      "Ambition: 10\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 2\n",
      "Intelligence: 7\n",
      "Fun: 6\n",
      "Ambition: 1\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 9\n",
      "Intelligence: 10\n",
      "Fun: 6\n",
      "Ambition: 9\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 1\n",
      "Intelligence: 6\n",
      "Fun: 7\n",
      "Ambition: 1\n",
      "\n",
      "Match 11] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 5\n",
      "Intelligence: 3\n",
      "Fun: 5\n",
      "Ambition: 2\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 10\n",
      "Sincerity: 5\n",
      "Intelligence: 2\n",
      "Fun: 7\n",
      "Ambition: 5\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 6\n",
      "Intelligence: 1\n",
      "Fun: 4\n",
      "Ambition: 2\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 6\n",
      "Intelligence: 2\n",
      "Fun: 5\n",
      "Ambition: 9\n",
      "\n",
      "Match 12] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 2\n",
      "Intelligence: 4\n",
      "Fun: 8\n",
      "Ambition: 9\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 5\n",
      "Intelligence: 5\n",
      "Fun: 1\n",
      "Ambition: 7\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 1\n",
      "Intelligence: 1\n",
      "Fun: 8\n",
      "Ambition: 9\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 5\n",
      "Intelligence: 5\n",
      "Fun: 9\n",
      "Ambition: 1\n",
      "\n",
      "Match 13] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 5\n",
      "Intelligence: 6\n",
      "Fun: 1\n",
      "Ambition: 3\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 10\n",
      "Sincerity: 2\n",
      "Intelligence: 4\n",
      "Fun: 8\n",
      "Ambition: 8\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 4\n",
      "Intelligence: 6\n",
      "Fun: 2\n",
      "Ambition: 5\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 3\n",
      "Sincerity: 1\n",
      "Intelligence: 5\n",
      "Fun: 10\n",
      "Ambition: 8\n",
      "\n",
      "Match 14] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 10\n",
      "Intelligence: 7\n",
      "Fun: 10\n",
      "Ambition: 2\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 2\n",
      "Intelligence: 7\n",
      "Fun: 2\n",
      "Ambition: 3\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 10\n",
      "Intelligence: 5\n",
      "Fun: 10\n",
      "Ambition: 2\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 1\n",
      "Intelligence: 7\n",
      "Fun: 3\n",
      "Ambition: 5\n",
      "\n",
      "Match 15] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 10\n",
      "Intelligence: 4\n",
      "Fun: 6\n",
      "Ambition: 10\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 3\n",
      "Intelligence: 5\n",
      "Fun: 6\n",
      "Ambition: 10\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 6\n",
      "Intelligence: 4\n",
      "Fun: 3\n",
      "Ambition: 9\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 6\n",
      "Intelligence: 5\n",
      "Fun: 5\n",
      "Ambition: 9\n",
      "\n",
      "Match 16] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 4\n",
      "Intelligence: 4\n",
      "Fun: 7\n",
      "Ambition: 6\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 8\n",
      "Intelligence: 3\n",
      "Fun: 4\n",
      "Ambition: 4\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 3\n",
      "Intelligence: 6\n",
      "Fun: 7\n",
      "Ambition: 7\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 4\n",
      "Intelligence: 2\n",
      "Fun: 1\n",
      "Ambition: 4\n",
      "\n",
      "Match 17] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 6\n",
      "Intelligence: 4\n",
      "Fun: 3\n",
      "Ambition: 4\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 2\n",
      "Intelligence: 1\n",
      "Fun: 3\n",
      "Ambition: 5\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 5\n",
      "Sincerity: 6\n",
      "Intelligence: 1\n",
      "Fun: 3\n",
      "Ambition: 2\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 2\n",
      "Intelligence: 1\n",
      "Fun: 4\n",
      "Ambition: 9\n",
      "\n",
      "Match 18] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 8\n",
      "Intelligence: 10\n",
      "Fun: 2\n",
      "Ambition: 5\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 2\n",
      "Sincerity: 6\n",
      "Intelligence: 2\n",
      "Fun: 5\n",
      "Ambition: 10\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 4\n",
      "Sincerity: 8\n",
      "Intelligence: 6\n",
      "Fun: 2\n",
      "Ambition: 5\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 1\n",
      "Sincerity: 5\n",
      "Intelligence: 2\n",
      "Fun: 3\n",
      "Ambition: 5\n",
      "\n",
      "Match 19] found with inputs:\n",
      "\n",
      "PARTNER A\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 1\n",
      "Intelligence: 1\n",
      "Fun: 3\n",
      "Ambition: 7\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 8\n",
      "Sincerity: 4\n",
      "Intelligence: 9\n",
      "Fun: 5\n",
      "Ambition: 3\n",
      "\n",
      "PARTNER B\n",
      "\n",
      "Self-ratings(1-10)\n",
      "Attractiveness: 6\n",
      "Sincerity: 2\n",
      "Intelligence: 4\n",
      "Fun: 3\n",
      "Ambition: 7\n",
      "\n",
      "Importance Ratings(1-10)\n",
      "Attractiveness: 9\n",
      "Sincerity: 2\n",
      "Intelligence: 9\n",
      "Fun: 6\n",
      "Ambition: 8\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('knn_model.pkl')\n",
    "\n",
    "# Initialize a counter for the number of matches found\n",
    "matches_found = 1\n",
    "\n",
    "# Define attribute names\n",
    "attributes = ['Attractiveness', 'Sincerity', 'Intelligence', 'Fun', 'Ambition']\n",
    "\n",
    "# Continue generating inputs until 10 matches are found\n",
    "while matches_found < 20:\n",
    "    # Generate random inputs for two partners\n",
    "    ratings = np.random.randint(1, 11, size=20)\n",
    "\n",
    "    # Preprocess the inputs to get the absolute difference of the partners' ratings\n",
    "    inputs = np.abs(ratings[:10] - ratings[10:])\n",
    "\n",
    "    # Feed the inputs to the model\n",
    "    prediction = model.predict([inputs])\n",
    "\n",
    "    # If the model predicts a match, print out the inputs and increment the counter\n",
    "    if prediction[0] == 1:\n",
    "        print(f'\\nMatch {matches_found}] found with inputs:')\n",
    "        for partner in ['A', 'B']:\n",
    "            print(f'\\nPARTNER {partner}')\n",
    "            print('\\nSelf-ratings(1-10)')\n",
    "            for i in range(5):\n",
    "                print(f'{attributes[i]}: {ratings[i]}')\n",
    "            print('\\nImportance Ratings(1-10)')\n",
    "            for i in range(5, 10):\n",
    "                print(f'{attributes[i-5]}: {ratings[i]}')\n",
    "            ratings = ratings[10:]\n",
    "        matches_found += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cc0cb-5573-4d5e-9a94-cfc65cb6fcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
